{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7384443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pcap_parse import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5571e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dir = \"D:\\\\Notebooks\\\\Datasets\\\\Network_dataset_pcaps\\\\normal_pcaps\"\n",
    "mal_dir = \"D:\\\\Notebooks\\\\Datasets\\\\Network_dataset_pcaps\\\\normal_attack_pcaps\"\n",
    "truth_dir = \"D:\\\\Notebooks\\\\Datasets\\\\truth\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459e5a6e",
   "metadata": {},
   "source": [
    "# Create ground truth dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e9fc63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(truth_dir)\n",
    "truth_df = pd.DataFrame()\n",
    "for dataset in files:\n",
    "    cur = pd.read_csv(truth_dir+\"\\\\\"+dataset)\n",
    "    truth_df = pd.concat([truth_df, cur], axis=0)\n",
    "truth_df.sort_values(by=['ts','src_ip','dst_ip','src_port','dst_port'], inplace=True)\n",
    "truth_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d70d1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "      <th>src_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>proto</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1556021410</td>\n",
       "      <td>192.168.1.30</td>\n",
       "      <td>42908</td>\n",
       "      <td>192.168.1.103</td>\n",
       "      <td>2046</td>\n",
       "      <td>tcp</td>\n",
       "      <td>scanning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1556021410</td>\n",
       "      <td>192.168.1.30</td>\n",
       "      <td>42909</td>\n",
       "      <td>192.168.1.103</td>\n",
       "      <td>2046</td>\n",
       "      <td>tcp</td>\n",
       "      <td>scanning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1556021410</td>\n",
       "      <td>192.168.1.30</td>\n",
       "      <td>50567</td>\n",
       "      <td>192.168.1.169</td>\n",
       "      <td>1106</td>\n",
       "      <td>tcp</td>\n",
       "      <td>scanning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ts        src_ip  src_port         dst_ip  dst_port proto      type\n",
       "0  1556021410  192.168.1.30     42908  192.168.1.103      2046   tcp  scanning\n",
       "1  1556021410  192.168.1.30     42909  192.168.1.103      2046   tcp  scanning\n",
       "2  1556021410  192.168.1.30     50567  192.168.1.169      1106   tcp  scanning"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f3469a",
   "metadata": {},
   "source": [
    "# Create dataframes for all malicious categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f519485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing backdoor\n",
      "1/1 : Using v1.0\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 188864\n",
      "Comparing row 18886 out of 188864\n",
      "Comparing row 37772 out of 188864\n",
      "Comparing row 56658 out of 188864\n",
      "Comparing row 75544 out of 188864\n",
      "Comparing row 94430 out of 188864\n",
      "Comparing row 113316 out of 188864\n",
      "Comparing row 132202 out of 188864\n",
      "Comparing row 151088 out of 188864\n",
      "Comparing row 169974 out of 188864\n",
      "Comparing row 188860 out of 188864\n",
      "Saving Dataframe...\n",
      "Parsing ddos\n",
      "1/12 : Using v2.4\n",
      "2/12 : Using v1.0\n",
      "3/12 : Using v1.0\n",
      "4/12 : Using v1.0\n",
      "5/12 : Using v2.4\n",
      "6/12 : Using v1.0\n",
      "7/12 : Using v1.0\n",
      "8/12 : Using v1.0\n",
      "9/12 : Using v1.0\n",
      "10/12 : Using v1.0\n",
      "11/12 : Using v1.0\n",
      "12/12 : Using v1.0\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 6031012\n",
      "Comparing row 603101 out of 6031012\n",
      "Comparing row 1206202 out of 6031012\n",
      "Comparing row 1809303 out of 6031012\n",
      "Comparing row 2412404 out of 6031012\n",
      "Comparing row 3015505 out of 6031012\n",
      "Comparing row 3618606 out of 6031012\n",
      "Comparing row 4221707 out of 6031012\n",
      "Comparing row 4824808 out of 6031012\n",
      "Comparing row 5427909 out of 6031012\n",
      "Comparing row 6031010 out of 6031012\n",
      "Saving Dataframe...\n",
      "Parsing dos\n",
      "1/5 : Using v2.4\n",
      "2/5 : Using v1.0\n",
      "3/5 : Using v1.0\n",
      "4/5 : Using v1.0\n",
      "5/5 : Using v1.0\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 196227\n",
      "Comparing row 19622 out of 196227\n",
      "Comparing row 39244 out of 196227\n",
      "Comparing row 58866 out of 196227\n",
      "Comparing row 78488 out of 196227\n",
      "Comparing row 98110 out of 196227\n",
      "Comparing row 117732 out of 196227\n",
      "Comparing row 137354 out of 196227\n",
      "Comparing row 156976 out of 196227\n",
      "Comparing row 176598 out of 196227\n",
      "Comparing row 196220 out of 196227\n",
      "Saving Dataframe...\n",
      "Parsing injection\n",
      "1/4 : Using v2.4\n",
      "2/4 : Using v1.0\n",
      "3/4 : Using v1.0\n",
      "4/4 : Using v2.4\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 451136\n",
      "Comparing row 45113 out of 451136\n",
      "Comparing row 90226 out of 451136\n",
      "Comparing row 135339 out of 451136\n",
      "Comparing row 180452 out of 451136\n",
      "Comparing row 225565 out of 451136\n",
      "Comparing row 270678 out of 451136\n",
      "Comparing row 315791 out of 451136\n",
      "Comparing row 360904 out of 451136\n",
      "Comparing row 406017 out of 451136\n",
      "Comparing row 451130 out of 451136\n",
      "Saving Dataframe...\n",
      "Parsing mitm\n",
      "1/4 : Using v2.4\n",
      "2/4 : Using v2.4\n",
      "3/4 : Using v2.4\n",
      "4/4 : Using v2.4\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 1010\n",
      "Comparing row 101 out of 1010\n",
      "Comparing row 202 out of 1010\n",
      "Comparing row 303 out of 1010\n",
      "Comparing row 404 out of 1010\n",
      "Comparing row 505 out of 1010\n",
      "Comparing row 606 out of 1010\n",
      "Comparing row 707 out of 1010\n",
      "Comparing row 808 out of 1010\n",
      "Comparing row 909 out of 1010\n",
      "Saving Dataframe...\n",
      "Parsing password\n",
      "1/5 : Using v2.4\n",
      "2/5 : Using v1.0\n",
      "3/5 : Using v1.0\n",
      "4/5 : Using v1.0\n",
      "5/5 : Using v1.0\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 1253031\n",
      "Comparing row 125303 out of 1253031\n",
      "Comparing row 250606 out of 1253031\n",
      "Comparing row 375909 out of 1253031\n",
      "Comparing row 501212 out of 1253031\n",
      "Comparing row 626515 out of 1253031\n",
      "Comparing row 751818 out of 1253031\n",
      "Comparing row 877121 out of 1253031\n",
      "Comparing row 1002424 out of 1253031\n",
      "Comparing row 1127727 out of 1253031\n",
      "Comparing row 1253030 out of 1253031\n",
      "Saving Dataframe...\n",
      "Parsing ransomware\n",
      "1/2 : Using v1.0\n",
      "2/2 : Using v1.0\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 5629\n",
      "Comparing row 562 out of 5629\n",
      "Comparing row 1124 out of 5629\n",
      "Comparing row 1686 out of 5629\n",
      "Comparing row 2248 out of 5629\n",
      "Comparing row 2810 out of 5629\n",
      "Comparing row 3372 out of 5629\n",
      "Comparing row 3934 out of 5629\n",
      "Comparing row 4496 out of 5629\n",
      "Comparing row 5058 out of 5629\n",
      "Comparing row 5620 out of 5629\n",
      "Saving Dataframe...\n",
      "Parsing scanning\n",
      "1/6 : Using v2.4\n",
      "2/6 : Using v2.4\n",
      "3/6 : Using v2.4\n",
      "4/6 : Using v2.4\n",
      "5/6 : Using v2.4\n",
      "6/6 : Using v1.0\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 7138336\n",
      "Comparing row 713833 out of 7138336\n",
      "Comparing row 1427666 out of 7138336\n",
      "Comparing row 2141499 out of 7138336\n",
      "Comparing row 2855332 out of 7138336\n",
      "Comparing row 3569165 out of 7138336\n",
      "Comparing row 4282998 out of 7138336\n",
      "Comparing row 4996831 out of 7138336\n",
      "Comparing row 5710664 out of 7138336\n",
      "Comparing row 6424497 out of 7138336\n",
      "Comparing row 7138330 out of 7138336\n",
      "Saving Dataframe...\n",
      "Parsing xss\n",
      "1/10 : Using v2.4\n",
      "2/10 : Using v1.0\n",
      "3/10 : Using v2.4\n",
      "4/10 : Using v1.0\n",
      "5/10 : Using v1.0\n",
      "6/10 : Using v1.0\n",
      "7/10 : Using v1.0\n",
      "8/10 : Using v1.0\n",
      "9/10 : Using v1.0\n",
      "10/10 : Using v1.0\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 2535943\n",
      "Comparing row 253594 out of 2535943\n",
      "Comparing row 507188 out of 2535943\n",
      "Comparing row 760782 out of 2535943\n",
      "Comparing row 1014376 out of 2535943\n",
      "Comparing row 1267970 out of 2535943\n",
      "Comparing row 1521564 out of 2535943\n",
      "Comparing row 1775158 out of 2535943\n",
      "Comparing row 2028752 out of 2535943\n",
      "Comparing row 2282346 out of 2535943\n",
      "Comparing row 2535940 out of 2535943\n",
      "Saving Dataframe...\n"
     ]
    }
   ],
   "source": [
    "skip_to = 0\n",
    "\n",
    "for x in range(len(os.listdir(mal_dir))-skip_to):\n",
    "    folder = os.listdir(mal_dir)[x+skip_to]\n",
    "    df = pd.DataFrame(columns=[\"p_bytes\",\"label\",\"ts\",\"src_ip\",\"dst_ip\",\"src_port\",\"dst_port\",\"pcap_ver\"])\n",
    "    i = 1\n",
    "    print(\"Parsing \"+folder)\n",
    "    for file_name in os.listdir(mal_dir+\"\\\\\"+folder):\n",
    "        print(str(i)+\"/\"+str(len(os.listdir(mal_dir+\"\\\\\"+folder))), end=\" : \")\n",
    "        df = parse_pcap(mal_dir+\"\\\\\"+folder+\"\\\\\"+file_name, df, 1)\n",
    "        i += 1\n",
    "    print(\"Sorting Dataframe...\")\n",
    "    df.sort_values(by=['ts','src_ip','dst_ip','src_port','dst_port'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(\"Matching ground truths...\")\n",
    "    truths = compare_truth(truth_df[truth_df['type']==folder].reset_index(drop=True), df)\n",
    "    df['val_label'] = truths\n",
    "    #print(df.head(3))\n",
    "    print(\"Saving Dataframe...\")\n",
    "    confirmed = df[df['val_label']==1].reset_index(drop=True)\n",
    "    confirmed.to_pickle('D:\\\\Notebooks\\\\Datasets\\\\final\\\\'+folder+'_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62e51795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backdoor_final.pkl\n",
      "ddos_final.pkl\n",
      "dos_final.pkl\n",
      "injection_final.pkl\n",
      "mitm_final.pkl\n",
      "password_final.pkl\n",
      "ransomware_final.pkl\n",
      "scanning_final.pkl\n",
      "xss_final.pkl\n",
      "17470536\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for file in os.listdir('D:\\\\Notebooks\\\\Datasets\\\\final'):\n",
    "    temp = pd.read_pickle('D:\\\\Notebooks\\\\Datasets\\\\final\\\\'+file)\n",
    "    print(file)\n",
    "    sum+=len(temp)\n",
    "    #print(temp['val_label'].value_counts())\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e037c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('D:\\\\Notebooks\\\\Datasets\\\\final\\\\mitm_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "725f4e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    944\n",
       "Name: val_label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['val_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9eda6e",
   "metadata": {},
   "source": [
    "# Create dataframe for normal category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e75087c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/15 : Using v1.0\n",
      "2/15 : Using v1.0\n",
      "3/15 : Using v1.0\n",
      "4/15 : Using v1.0\n",
      "5/15 : Using v1.0\n",
      "6/15 : Using v1.0\n",
      "7/15 : Using v1.0\n",
      "8/15 : Using v1.0\n",
      "9/15 : Using v1.0\n",
      "10/15 : Using v1.0\n",
      "11/15 : Using v1.0\n",
      "12/15 : Using v1.0\n",
      "13/15 : Using v1.0\n",
      "14/15 : Using v2.4\n",
      "15/15 : Using v2.4\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"p_bytes\",\"label\",\"ts\",\"src_ip\",\"dst_ip\",\"src_port\",\"dst_port\",\"pcap_ver\"])\n",
    "i = 1\n",
    "for file_name in os.listdir(normal_dir):\n",
    "    print(str(i)+\"/\"+str(len(os.listdir(normal_dir))), end=\" : \")\n",
    "    df = parse_pcap(normal_dir+\"\\\\\"+file_name, df, 0)\n",
    "    i+=1\n",
    "\n",
    "df.sort_values(by=['ts','src_ip','dst_ip','src_port','dst_port'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab99052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df[df['dst_port']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f841266",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3db58de",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.to_pickle('D:\\\\Notebooks\\\\Datasets\\\\final\\\\normal_final.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672f536d",
   "metadata": {},
   "source": [
    "# Create tokenize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7b3997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_150(data):\n",
    "    toks = list(data[0:150])\n",
    "    toks += [0] * (150 - len(toks)) # Padding to 150\n",
    "    #return tf.convert_to_tensor(np.asarray(toks))\n",
    "    return np.array(toks, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7499f84b",
   "metadata": {},
   "source": [
    "# Create final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151de51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(columns=[\"p_bytes\",\"label\",\"ts\",\"src_ip\",\"dst_ip\",\"src_port\",\"dst_port\",\"pcap_ver\"])\n",
    "\n",
    "for file in os.listdir('D:\\\\Notebooks\\\\Datasets\\\\final'):\n",
    "    temp = pd.read_pickle('D:\\\\Notebooks\\\\Datasets\\\\final\\\\'+file)\n",
    "    final = pd.concat([final, temp])\n",
    "\n",
    "final.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76fd347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.drop('val_label', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c092506f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_bytes</th>\n",
       "      <th>label</th>\n",
       "      <th>ts</th>\n",
       "      <th>src_ip</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>pcap_ver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'\\xa4\\x91\\xb1\\x1eW\\x90\\x00\\x0c)[s[\\x08\\x00E\\x...</td>\n",
       "      <td>1</td>\n",
       "      <td>1556436599</td>\n",
       "      <td>192.168.1.37</td>\n",
       "      <td>121.0.0.42</td>\n",
       "      <td>47975</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'\\x00\\x0c)\\xa4\\x03\\xf4\\x00\\x0c)[s[\\x08\\x00E\\x...</td>\n",
       "      <td>1</td>\n",
       "      <td>1556436603</td>\n",
       "      <td>192.168.1.37</td>\n",
       "      <td>192.168.1.193</td>\n",
       "      <td>4444</td>\n",
       "      <td>49178</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'\\x00\\x0c)[s[\\x00\\x0c)\\xa4\\x03\\xf4\\x08\\x00E\\x...</td>\n",
       "      <td>1</td>\n",
       "      <td>1556436611</td>\n",
       "      <td>192.168.1.193</td>\n",
       "      <td>192.168.1.37</td>\n",
       "      <td>49180</td>\n",
       "      <td>8080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             p_bytes label          ts  \\\n",
       "0  b'\\xa4\\x91\\xb1\\x1eW\\x90\\x00\\x0c)[s[\\x08\\x00E\\x...     1  1556436599   \n",
       "1  b'\\x00\\x0c)\\xa4\\x03\\xf4\\x00\\x0c)[s[\\x08\\x00E\\x...     1  1556436603   \n",
       "2  b'\\x00\\x0c)[s[\\x00\\x0c)\\xa4\\x03\\xf4\\x08\\x00E\\x...     1  1556436611   \n",
       "\n",
       "          src_ip         dst_ip src_port dst_port pcap_ver  \n",
       "0   192.168.1.37     121.0.0.42    47975      123        1  \n",
       "1   192.168.1.37  192.168.1.193     4444    49178        1  \n",
       "2  192.168.1.193   192.168.1.37    49180     8080        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8227bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_pickle('D:\\\\Notebooks\\\\Datasets\\\\complete_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "019ded5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17470536\n",
       "0     9565467\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "509117a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.drop(final[final['label'] == 1].sample(n=12470536).index, inplace=True)\n",
    "final.drop(final[final['label'] == 0].sample(n=4565467).index, inplace=True)\n",
    "final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1275616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5000000\n",
       "0    5000000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af8b8512",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_pickle('D:\\\\Notebooks\\\\Datasets\\\\10m_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "063aea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final['tok150'] = final['p_bytes'].apply(tok_150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e75d10d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_pickle('D:\\\\Notebooks\\\\Datasets\\\\10m_final_tok.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908123d7",
   "metadata": {},
   "source": [
    "# Create deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5e33c4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67c11a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d456f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final = pd.read_pickle('D:\\\\Notebooks\\\\Datasets\\\\10m_final_tok.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "67214742",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final['tok150'], final['label'], test_size=0.2)\n",
    "X_train = np.stack(X_train.to_numpy())\n",
    "X_test = np.stack(X_test.to_numpy())\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1745fef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f7978d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 150, 8)            2048      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1201      \n",
      "=================================================================\n",
      "Total params: 3,249\n",
      "Trainable params: 3,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Embedding(input_dim=256, output_dim=8, input_length=150))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "#model.add(layers.Dense(256, activation=\"relu\", input_shape=(len(imp_cols)-1,)))\n",
    "#model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "12942f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "765c847b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250000/250000 [==============================] - 517s 2ms/step - loss: 3.0517e-04 - accuracy: 0.9999\n",
      "Epoch 2/10\n",
      "250000/250000 [==============================] - 514s 2ms/step - loss: 6.4343e-10 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "250000/250000 [==============================] - 514s 2ms/step - loss: 1.1882e-10 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "250000/250000 [==============================] - 513s 2ms/step - loss: 2.8452e-11 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "250000/250000 [==============================] - 516s 2ms/step - loss: 2.0015e-11 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "250000/250000 [==============================] - 513s 2ms/step - loss: 1.6241e-11 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "250000/250000 [==============================] - 510s 2ms/step - loss: 1.3761e-11 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "250000/250000 [==============================] - 515s 2ms/step - loss: 1.1815e-11 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "250000/250000 [==============================] - 516s 2ms/step - loss: 1.0477e-11 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "250000/250000 [==============================] - 515s 2ms/step - loss: 9.5159e-12 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x=X_train, y=y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93a51a73",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ethan\\AppData\\Local\\Temp\\ipykernel_8324\\625517341.py:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  hist = model.fit(x=X_train.astype(np.float), y=y_train, batch_size=32, epochs=10, validation_data=(X_test.astype(np.float), y_test))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1143\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_coordinator \u001b[38;5;241m=\u001b[39m cluster_coordinator\u001b[38;5;241m.\u001b[39mClusterCoordinator(\n\u001b[0;32m   1138\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy)\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), \\\n\u001b[0;32m   1141\u001b[0m      training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1142\u001b[0m   \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[1;32m-> 1143\u001b[0m   data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m      \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m      \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m      \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1159\u001b[0m   \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1400\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1399\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1155\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1152\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_value \u001b[38;5;241m=\u001b[39m steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1154\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1169\u001b[0m strategy \u001b[38;5;241m=\u001b[39m ds_context\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:247\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    237\u001b[0m              x,\n\u001b[0;32m    238\u001b[0m              y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m              shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    245\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    246\u001b[0m   \u001b[38;5;28msuper\u001b[39m(TensorLikeDataAdapter, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 247\u001b[0m   x, y, sample_weights \u001b[38;5;241m=\u001b[39m \u001b[43m_process_tensorlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m   sample_weight_modes \u001b[38;5;241m=\u001b[39m broadcast_sample_weight_modes(\n\u001b[0;32m    249\u001b[0m       sample_weights, sample_weight_modes)\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;66;03m# If sample_weights are not specified for an output use 1.0 as weights.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1048\u001b[0m, in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n\u001b[0;32m   1046\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m-> 1048\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_numpy_and_scipy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mlist_to_tuple(inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py:1043\u001b[0m, in \u001b[0;36m_process_tensorlike.<locals>._convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1041\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[0;32m   1042\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[1;32m-> 1043\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor_v2_with_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_scipy_sparse(x):\n\u001b[0;32m   1045\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1430\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[0;32m   1369\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1370\u001b[0m   \u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[0;32m   1371\u001b[0m \n\u001b[0;32m   1372\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1430\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1431\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1436\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1435\u001b[0m   \u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1436\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1440\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m      \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1566\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1561\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1563\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1566\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1569\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:52\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[0;32m     51\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    176\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:283\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    282\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 283\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[0;32m    286\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:308\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    307\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 308\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    105\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "#hist = model.fit(x=X_train.astype(np.float32), y=y_train, batch_size=32, epochs=10, validation_data=(X_test.astype(np.float32), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84e91f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62500/62500 [==============================] - 71s 1ms/step - loss: 2.0281e-11 - accuracy: 1.0000\n",
      "Test loss: 2.02811829830285e-11\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c4081c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7570de37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       [1.0000000e+00],\n",
       "       ...,\n",
       "       [5.6603840e-19],\n",
       "       [9.2418814e-26],\n",
       "       [1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8743d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_binary = []\n",
    "for pred in y_pred:\n",
    "    if pred >= .5:\n",
    "        y_pred_binary.append(1)\n",
    "    else:\n",
    "        y_pred_binary.append(0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1e3594df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e94d3d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 999598,       0],\n",
       "       [      0, 1000402]], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df9de07",
   "metadata": {},
   "source": [
    "### Since accuracy is 100% maybe there is some identifier in the data that should not be included, such as the bytes indicating the ip addresses\n",
    "\n",
    "I will change pcap_parse to be deindentify ip addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13da2b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing backdoor\n",
      "1/1 : Using v1.0\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 188864\n",
      "Comparing row 18886 out of 188864\n",
      "Comparing row 37772 out of 188864\n",
      "Comparing row 56658 out of 188864\n",
      "Comparing row 75544 out of 188864\n",
      "Comparing row 94430 out of 188864\n",
      "Comparing row 113316 out of 188864\n",
      "Comparing row 132202 out of 188864\n",
      "Comparing row 151088 out of 188864\n",
      "Comparing row 169974 out of 188864\n",
      "Comparing row 188860 out of 188864\n",
      "Saving Dataframe...\n",
      "Parsing ddos\n",
      "1/12 : Using v2.4\n",
      "2/12 : Using v1.0\n",
      "3/12 : Using v1.0\n",
      "4/12 : Using v1.0\n",
      "5/12 : Using v2.4\n",
      "6/12 : Using v1.0\n",
      "7/12 : Using v1.0\n",
      "8/12 : Using v1.0\n",
      "9/12 : Using v1.0\n",
      "10/12 : Using v1.0\n",
      "11/12 : Using v1.0\n",
      "12/12 : Using v1.0\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 6031012\n",
      "Comparing row 603101 out of 6031012\n",
      "Comparing row 1206202 out of 6031012\n",
      "Comparing row 1809303 out of 6031012\n",
      "Comparing row 2412404 out of 6031012\n",
      "Comparing row 3015505 out of 6031012\n",
      "Comparing row 3618606 out of 6031012\n",
      "Comparing row 4221707 out of 6031012\n",
      "Comparing row 4824808 out of 6031012\n",
      "Comparing row 5427909 out of 6031012\n",
      "Comparing row 6031010 out of 6031012\n",
      "Saving Dataframe...\n",
      "Parsing dos\n",
      "1/5 : Using v2.4\n",
      "2/5 : Using v1.0\n",
      "3/5 : Using v1.0\n",
      "4/5 : Using v1.0\n",
      "5/5 : Using v1.0\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 196227\n",
      "Comparing row 19622 out of 196227\n",
      "Comparing row 39244 out of 196227\n",
      "Comparing row 58866 out of 196227\n",
      "Comparing row 78488 out of 196227\n",
      "Comparing row 98110 out of 196227\n",
      "Comparing row 117732 out of 196227\n",
      "Comparing row 137354 out of 196227\n",
      "Comparing row 156976 out of 196227\n",
      "Comparing row 176598 out of 196227\n",
      "Comparing row 196220 out of 196227\n",
      "Saving Dataframe...\n",
      "Parsing injection\n",
      "1/4 : Using v2.4\n",
      "2/4 : Using v1.0\n",
      "3/4 : Using v1.0\n",
      "4/4 : Using v2.4\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 451136\n",
      "Comparing row 45113 out of 451136\n",
      "Comparing row 90226 out of 451136\n",
      "Comparing row 135339 out of 451136\n",
      "Comparing row 180452 out of 451136\n",
      "Comparing row 225565 out of 451136\n",
      "Comparing row 270678 out of 451136\n",
      "Comparing row 315791 out of 451136\n",
      "Comparing row 360904 out of 451136\n",
      "Comparing row 406017 out of 451136\n",
      "Comparing row 451130 out of 451136\n",
      "Saving Dataframe...\n",
      "Parsing mitm\n",
      "1/4 : Using v2.4\n",
      "2/4 : Using v2.4\n",
      "3/4 : Using v2.4\n",
      "4/4 : Using v2.4\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 1010\n",
      "Comparing row 101 out of 1010\n",
      "Comparing row 202 out of 1010\n",
      "Comparing row 303 out of 1010\n",
      "Comparing row 404 out of 1010\n",
      "Comparing row 505 out of 1010\n",
      "Comparing row 606 out of 1010\n",
      "Comparing row 707 out of 1010\n",
      "Comparing row 808 out of 1010\n",
      "Comparing row 909 out of 1010\n",
      "Saving Dataframe...\n",
      "Parsing password\n",
      "1/5 : Using v2.4\n",
      "2/5 : Using v1.0\n",
      "3/5 : Using v1.0\n",
      "4/5 : Using v1.0\n",
      "5/5 : Using v1.0\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 1253031\n",
      "Comparing row 125303 out of 1253031\n",
      "Comparing row 250606 out of 1253031\n",
      "Comparing row 375909 out of 1253031\n",
      "Comparing row 501212 out of 1253031\n",
      "Comparing row 626515 out of 1253031\n",
      "Comparing row 751818 out of 1253031\n",
      "Comparing row 877121 out of 1253031\n",
      "Comparing row 1002424 out of 1253031\n",
      "Comparing row 1127727 out of 1253031\n",
      "Comparing row 1253030 out of 1253031\n",
      "Saving Dataframe...\n",
      "Parsing ransomware\n",
      "1/2 : Using v1.0\n",
      "2/2 : Using v1.0\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 5629\n",
      "Comparing row 562 out of 5629\n",
      "Comparing row 1124 out of 5629\n",
      "Comparing row 1686 out of 5629\n",
      "Comparing row 2248 out of 5629\n",
      "Comparing row 2810 out of 5629\n",
      "Comparing row 3372 out of 5629\n",
      "Comparing row 3934 out of 5629\n",
      "Comparing row 4496 out of 5629\n",
      "Comparing row 5058 out of 5629\n",
      "Comparing row 5620 out of 5629\n",
      "Saving Dataframe...\n",
      "Parsing scanning\n",
      "1/6 : Using v2.4\n",
      "2/6 : Using v2.4\n",
      "3/6 : Using v2.4\n",
      "4/6 : Using v2.4\n",
      "5/6 : Using v2.4\n",
      "6/6 : Using v1.0\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 7138336\n",
      "Comparing row 713833 out of 7138336\n",
      "Comparing row 1427666 out of 7138336\n",
      "Comparing row 2141499 out of 7138336\n",
      "Comparing row 2855332 out of 7138336\n",
      "Comparing row 3569165 out of 7138336\n",
      "Comparing row 4282998 out of 7138336\n",
      "Comparing row 4996831 out of 7138336\n",
      "Comparing row 5710664 out of 7138336\n",
      "Comparing row 6424497 out of 7138336\n",
      "Comparing row 7138330 out of 7138336\n",
      "Saving Dataframe...\n",
      "Parsing xss\n",
      "1/10 : Using v2.4\n",
      "2/10 : Using v1.0\n",
      "3/10 : Using v2.4\n",
      "4/10 : Using v1.0\n",
      "5/10 : Using v1.0\n",
      "6/10 : Using v1.0\n",
      "7/10 : Using v1.0\n",
      "8/10 : Using v1.0\n",
      "9/10 : Using v1.0\n",
      "10/10 : Using v1.0\n",
      "Sorting Dataframe...\n",
      "Matching ground truths...\n",
      "Comparing row 0 out of 2535943\n",
      "Comparing row 253594 out of 2535943\n",
      "Comparing row 507188 out of 2535943\n",
      "Comparing row 760782 out of 2535943\n",
      "Comparing row 1014376 out of 2535943\n",
      "Comparing row 1267970 out of 2535943\n",
      "Comparing row 1521564 out of 2535943\n",
      "Comparing row 1775158 out of 2535943\n",
      "Comparing row 2028752 out of 2535943\n",
      "Comparing row 2282346 out of 2535943\n",
      "Comparing row 2535940 out of 2535943\n",
      "Saving Dataframe...\n"
     ]
    }
   ],
   "source": [
    "# Remaking the dataframes with no ip addresses in the data\n",
    "\n",
    "skip_to = 0\n",
    "for x in range(len(os.listdir(mal_dir))-skip_to):\n",
    "    folder = os.listdir(mal_dir)[x+skip_to]\n",
    "    df = pd.DataFrame(columns=[\"p_bytes\",\"label\",\"ts\",\"src_ip\",\"dst_ip\",\"src_port\",\"dst_port\",\"pcap_ver\"])\n",
    "    i = 1\n",
    "    print(\"Parsing \"+folder)\n",
    "    for file_name in os.listdir(mal_dir+\"\\\\\"+folder):\n",
    "        print(str(i)+\"/\"+str(len(os.listdir(mal_dir+\"\\\\\"+folder))), end=\" : \")\n",
    "        df = parse_pcap(mal_dir+\"\\\\\"+folder+\"\\\\\"+file_name, df, 1, hide_identifiers=True)\n",
    "        i += 1\n",
    "    print(\"Sorting Dataframe...\")\n",
    "    df.sort_values(by=['ts','src_ip','dst_ip','src_port','dst_port'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(\"Matching ground truths...\")\n",
    "    truths = compare_truth(truth_df[truth_df['type']==folder].reset_index(drop=True), df)\n",
    "    df['val_label'] = truths\n",
    "    #print(df.head(3))\n",
    "    print(\"Saving Dataframe...\")\n",
    "    confirmed = df[df['val_label']==1].reset_index(drop=True)\n",
    "    confirmed.to_pickle('D:\\\\Notebooks\\\\Datasets\\\\final\\\\'+folder+'_final_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e735d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/15 : Using v1.0\n",
      "2/15 : Using v1.0\n",
      "3/15 : Using v1.0\n",
      "4/15 : Using v1.0\n",
      "5/15 : Using v1.0\n",
      "6/15 : Using v1.0\n",
      "7/15 : Using v1.0\n",
      "8/15 : Using v1.0\n",
      "9/15 : Using v1.0\n",
      "10/15 : Using v1.0\n",
      "11/15 : Using v1.0\n",
      "12/15 : Using v1.0\n",
      "13/15 : Using v1.0\n",
      "14/15 : Using v2.4\n",
      "15/15 : Using v2.4\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"p_bytes\",\"label\",\"ts\",\"src_ip\",\"dst_ip\",\"src_port\",\"dst_port\",\"pcap_ver\"])\n",
    "i = 1\n",
    "for file_name in os.listdir(normal_dir):\n",
    "    print(str(i)+\"/\"+str(len(os.listdir(normal_dir))), end=\" : \")\n",
    "    df = parse_pcap(normal_dir+\"\\\\\"+file_name, df, 0, hide_identifiers=True)\n",
    "    i+=1\n",
    "df.sort_values(by=['ts','src_ip','dst_ip','src_port','dst_port'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "temp = df[df['dst_port']!=0]\n",
    "temp.reset_index(drop=True, inplace=True)\n",
    "temp.to_pickle('D:\\\\Notebooks\\\\Datasets\\\\final\\\\normal_final_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0af4bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(columns=[\"p_bytes\",\"label\",\"ts\",\"src_ip\",\"dst_ip\",\"src_port\",\"dst_port\",\"pcap_ver\"])\n",
    "\n",
    "for file in os.listdir('D:\\\\Notebooks\\\\Datasets\\\\final'):\n",
    "    temp = pd.read_pickle('D:\\\\Notebooks\\\\Datasets\\\\final\\\\'+file)\n",
    "    final = pd.concat([final, temp])\n",
    "\n",
    "final.reset_index(drop=True, inplace=True)\n",
    "final.drop('val_label', axis=1, inplace=True)\n",
    "final.drop(final[final['label'] == 1].sample(n=12470536).index, inplace=True)\n",
    "final.drop(final[final['label'] == 0].sample(n=4565467).index, inplace=True)\n",
    "final.reset_index(drop=True, inplace=True)\n",
    "final['tok150'] = final['p_bytes'].apply(tok_150)\n",
    "final.to_pickle('D:\\\\Notebooks\\\\Datasets\\\\10m_final_tok_2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4809f661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd6e2fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final['tok150'], final['label'], test_size=0.2)\n",
    "X_train = np.stack(X_train.to_numpy())\n",
    "X_test = np.stack(X_test.to_numpy())\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c84ce497",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa020310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 8)            2048      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 1201      \n",
      "=================================================================\n",
      "Total params: 3,249\n",
      "Trainable params: 3,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.Sequential()\n",
    "\n",
    "model2.add(layers.Embedding(input_dim=256, output_dim=8, input_length=150))\n",
    "model2.add(layers.Flatten())\n",
    "\n",
    "#model.add(layers.Dense(256, activation=\"relu\", input_shape=(len(imp_cols)-1,)))\n",
    "#model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model2.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be1afcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56b8d151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250000/250000 [==============================] - 1486s 6ms/step - loss: 3.2403e-04 - accuracy: 0.9999\n",
      "Epoch 2/10\n",
      "250000/250000 [==============================] - 1474s 6ms/step - loss: 2.0658e-06 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "250000/250000 [==============================] - 1496s 6ms/step - loss: 9.3643e-07 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "250000/250000 [==============================] - 1405s 6ms/step - loss: 2.7380e-07 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "250000/250000 [==============================] - 1452s 6ms/step - loss: 6.6380e-07 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "250000/250000 [==============================] - 1423s 6ms/step - loss: 4.8165e-07 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "250000/250000 [==============================] - 1449s 6ms/step - loss: 8.0636e-08 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "250000/250000 [==============================] - 1120s 4ms/step - loss: 5.2239e-09 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "250000/250000 [==============================] - 520s 2ms/step - loss: 6.3449e-10 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "250000/250000 [==============================] - 519s 2ms/step - loss: 1.8218e-10 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist2 = model2.fit(x=X_train, y=y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9004215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62500/62500 [==============================] - 72s 1ms/step - loss: 5.2701e-06 - accuracy: 1.0000\n",
      "Test loss: 5.2700920605275314e-06\n",
      "Test accuracy: 0.9999989867210388\n"
     ]
    }
   ],
   "source": [
    "score = model2.evaluate(X_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46f37d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict(X_test)\n",
    "y_pred_binary = []\n",
    "for pred in y_pred:\n",
    "    if pred >= .5:\n",
    "        y_pred_binary.append(1)\n",
    "    else:\n",
    "        y_pred_binary.append(0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0bd0f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ec6090d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 999664,       0],\n",
       "       [      2, 1000334]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c49be0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   3, ...,   0,   0,   0],\n",
       "       [  0,   3,   0, ...,   0,   0,   0],\n",
       "       [  0,   3,   0, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,   0,   0],\n",
       "       [  0,  12,  41, ...,   0,   0,   0],\n",
       "       [  0,   4,   0, ...,  58,  34, 112]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "534291dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b8111ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   3,   4,   0,   6,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   8,   0,  69,   0,   0,  52, 247, 234,  64,   0,  64,   6,\n",
       "       190,  88,   0,   0,   0,   0,   0,   0,   0,   0, 202,  70,   7,\n",
       "        88, 248, 217, 239, 146, 191, 117, 172,  82, 128,  16,  14,  53,\n",
       "       132, 167,   0,   0,   1,   1,   8,  10,  70,  14,  70, 184,  70,\n",
       "        14,  70, 184,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef3aa078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   3,   0,   1,   0,   6,   0,  12,  41,  91, 115,  91,  61,\n",
       "        34,   8,   0,  69,   0,   0,  60, 105, 238,  64,   0,  64,   6,\n",
       "        76, 191,   0,   0,   0,   0,   0,   0,   0,   0, 167,  70,   0,\n",
       "        21, 178, 244, 241, 218,   0,   0,   0,   0, 160,   2, 114,  16,\n",
       "       215,  22,   0,   0,   2,   4,   5, 180,   4,   2,   8,  10,  67,\n",
       "        59, 235,  99,   0,   0,   0,   0,   1,   3,   3,   7,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4b537b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using v1.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"p_bytes\",\"label\",\"ts\",\"src_ip\",\"dst_ip\",\"src_port\",\"dst_port\",\"pcap_ver\"])\n",
    "df = parse_pcap(\"D:\\\\Notebooks\\\\Datasets\\\\testing.pcapng\", df, 0, hide_identifiers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6a159c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['src_ip']==\"0.0.0.0\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8e8110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(853, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6462ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df['tok150'] = df['p_bytes'].apply(tok_150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "400f8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = df['tok150']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8de7d58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.stack(test_x.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "18d8f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model2.predict(test_x)\n",
    "y_pred_binary2 = []\n",
    "for pred in y_pred2:\n",
    "    if pred >= .5:\n",
    "        y_pred_binary2.append(1)\n",
    "    else:\n",
    "        y_pred_binary2.append(0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "384c78cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([58, 80], dtype=int64))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred_binary2, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0d2fdd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.771551724137931"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "179/232"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a00c847",
   "metadata": {},
   "source": [
    "## Added my own packets to normal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "03f543d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/12 : Using v1.0\n",
      "2/12 : Using v1.0\n",
      "3/12 : Using v1.0\n",
      "4/12 : Using v1.0\n",
      "5/12 : Using v1.0\n",
      "6/12 : Using v1.0\n",
      "7/12 : Using v1.0\n",
      "8/12 : Using v1.0\n",
      "9/12 : Using v1.0\n",
      "10/12 : Using v1.0\n",
      "11/12 : Using v2.4\n",
      "12/12 : Using v1.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"p_bytes\",\"label\",\"ts\",\"src_ip\",\"dst_ip\",\"src_port\",\"dst_port\",\"pcap_ver\"])\n",
    "i = 1\n",
    "for file_name in os.listdir(normal_dir):\n",
    "    print(str(i)+\"/\"+str(len(os.listdir(normal_dir))), end=\" : \")\n",
    "    df = parse_pcap(normal_dir+\"\\\\\"+file_name, df, 0)\n",
    "    i+=1\n",
    "\n",
    "df.sort_values(by=['ts','src_ip','dst_ip','src_port','dst_port'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "temp = df[df['dst_port']!=0]\n",
    "temp = temp[temp['src_ip']!=\"127.0.0.1\"]\n",
    "temp.reset_index(drop=True, inplace=True)\n",
    "temp.to_pickle('D:\\\\Notebooks\\\\Datasets\\\\final\\\\normal_final_3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b39de56e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_bytes</th>\n",
       "      <th>label</th>\n",
       "      <th>ts</th>\n",
       "      <th>src_ip</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>pcap_ver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'\\x00\\x00\\x00\\x01\\x00\\x06\\x00\\x0c)\\xd2\\xb0\\x0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1554220325</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>192.168.1.190</td>\n",
       "      <td>1880</td>\n",
       "      <td>43539</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'\\x00\\x00\\x00\\x01\\x00\\x06\\x00\\x0c)\\xd2\\xb0\\x0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1554220325</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>192.168.1.190</td>\n",
       "      <td>1880</td>\n",
       "      <td>43539</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'\\x00\\x00\\x00\\x01\\x00\\x06\\x00\\x0c)\\xd2\\xb0\\x0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1554220325</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>192.168.1.190</td>\n",
       "      <td>1880</td>\n",
       "      <td>43539</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'\\x00\\x00\\x00\\x01\\x00\\x06\\x00\\x0c)\\xd2\\xb0\\x0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1554220325</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>192.168.1.190</td>\n",
       "      <td>1880</td>\n",
       "      <td>43539</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'\\x00\\x00\\x00\\x01\\x00\\x06\\x00\\x0c)\\xd2\\xb0\\x0...</td>\n",
       "      <td>0</td>\n",
       "      <td>1554220325</td>\n",
       "      <td>192.168.1.152</td>\n",
       "      <td>192.168.1.190</td>\n",
       "      <td>1880</td>\n",
       "      <td>43539</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050101</th>\n",
       "      <td>b'\\x01\\x00^\\x7f\\xff\\xfa\\x00b\\xec\\xbb\\xf4\\xa3\\x...</td>\n",
       "      <td>0</td>\n",
       "      <td>1682024250</td>\n",
       "      <td>10.1.96.182</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>56937</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050102</th>\n",
       "      <td>b'\\xd8^\\xd3\\x8a3B\\x00b\\xec\\xbb\\xf4\\xa3\\x08\\x00...</td>\n",
       "      <td>0</td>\n",
       "      <td>1682024250</td>\n",
       "      <td>162.159.130.234</td>\n",
       "      <td>10.1.80.118</td>\n",
       "      <td>443</td>\n",
       "      <td>7068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050103</th>\n",
       "      <td>b'\\xd8^\\xd3\\x8a3B\\x00b\\xec\\xbb\\xf4\\xa3\\x08\\x00...</td>\n",
       "      <td>0</td>\n",
       "      <td>1682024250</td>\n",
       "      <td>162.254.192.75</td>\n",
       "      <td>10.1.80.118</td>\n",
       "      <td>27037</td>\n",
       "      <td>42217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050104</th>\n",
       "      <td>b'\\xd8^\\xd3\\x8a3B\\x04\\xd6\\x0e\\x1d\\x89x\\x08\\x00...</td>\n",
       "      <td>0</td>\n",
       "      <td>1682024251</td>\n",
       "      <td>10.1.88.132</td>\n",
       "      <td>10.1.80.118</td>\n",
       "      <td>1900</td>\n",
       "      <td>58112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6050105</th>\n",
       "      <td>b'ters provided by dumpcap\\x02\\x00\\x08\\x00\\xca...</td>\n",
       "      <td>0</td>\n",
       "      <td>1682024251</td>\n",
       "      <td>8.0.202.249</td>\n",
       "      <td>5.0.202.4</td>\n",
       "      <td>26205</td>\n",
       "      <td>768</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6050106 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   p_bytes label          ts  \\\n",
       "0        b'\\x00\\x00\\x00\\x01\\x00\\x06\\x00\\x0c)\\xd2\\xb0\\x0...     0  1554220325   \n",
       "1        b'\\x00\\x00\\x00\\x01\\x00\\x06\\x00\\x0c)\\xd2\\xb0\\x0...     0  1554220325   \n",
       "2        b'\\x00\\x00\\x00\\x01\\x00\\x06\\x00\\x0c)\\xd2\\xb0\\x0...     0  1554220325   \n",
       "3        b'\\x00\\x00\\x00\\x01\\x00\\x06\\x00\\x0c)\\xd2\\xb0\\x0...     0  1554220325   \n",
       "4        b'\\x00\\x00\\x00\\x01\\x00\\x06\\x00\\x0c)\\xd2\\xb0\\x0...     0  1554220325   \n",
       "...                                                    ...   ...         ...   \n",
       "6050101  b'\\x01\\x00^\\x7f\\xff\\xfa\\x00b\\xec\\xbb\\xf4\\xa3\\x...     0  1682024250   \n",
       "6050102  b'\\xd8^\\xd3\\x8a3B\\x00b\\xec\\xbb\\xf4\\xa3\\x08\\x00...     0  1682024250   \n",
       "6050103  b'\\xd8^\\xd3\\x8a3B\\x00b\\xec\\xbb\\xf4\\xa3\\x08\\x00...     0  1682024250   \n",
       "6050104  b'\\xd8^\\xd3\\x8a3B\\x04\\xd6\\x0e\\x1d\\x89x\\x08\\x00...     0  1682024251   \n",
       "6050105  b'ters provided by dumpcap\\x02\\x00\\x08\\x00\\xca...     0  1682024251   \n",
       "\n",
       "                  src_ip           dst_ip src_port dst_port pcap_ver  \n",
       "0          192.168.1.152    192.168.1.190     1880    43539        1  \n",
       "1          192.168.1.152    192.168.1.190     1880    43539        1  \n",
       "2          192.168.1.152    192.168.1.190     1880    43539        1  \n",
       "3          192.168.1.152    192.168.1.190     1880    43539        1  \n",
       "4          192.168.1.152    192.168.1.190     1880    43539        1  \n",
       "...                  ...              ...      ...      ...      ...  \n",
       "6050101      10.1.96.182  239.255.255.250    56937     1900        1  \n",
       "6050102  162.159.130.234      10.1.80.118      443     7068        1  \n",
       "6050103   162.254.192.75      10.1.80.118    27037    42217        1  \n",
       "6050104      10.1.88.132      10.1.80.118     1900    58112        1  \n",
       "6050105      8.0.202.249        5.0.202.4    26205      768        1  \n",
       "\n",
       "[6050106 rows x 8 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c9304",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(columns=[\"p_bytes\",\"label\",\"ts\",\"src_ip\",\"dst_ip\",\"src_port\",\"dst_port\",\"pcap_ver\"])\n",
    "\n",
    "for file in os.listdir('D:\\\\Notebooks\\\\Datasets\\\\final'):\n",
    "    temp = pd.read_pickle('D:\\\\Notebooks\\\\Datasets\\\\final\\\\'+file)\n",
    "    final = pd.concat([final, temp])\n",
    "\n",
    "final.reset_index(drop=True, inplace=True)\n",
    "final.drop('val_label', axis=1, inplace=True)\n",
    "final.drop(final[final['label'] == 1].sample(n=12470536).index, inplace=True)\n",
    "final.drop(final[final['label'] == 0].sample(n=1050105).index, inplace=True)\n",
    "final.reset_index(drop=True, inplace=True)\n",
    "final['tok150'] = final['p_bytes'].apply(tok_150)\n",
    "final.to_pickle('D:\\\\Notebooks\\\\Datasets\\\\10m_final_tok_3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final['tok150'], final['label'], test_size=0.2)\n",
    "X_train = np.stack(X_train.to_numpy())\n",
    "X_test = np.stack(X_test.to_numpy())\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "y_train = y_train.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1183d89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = keras.Sequential()\n",
    "\n",
    "model3.add(layers.Embedding(input_dim=256, output_dim=8, input_length=150))\n",
    "model3.add(layers.Flatten())\n",
    "#model.add(layers.Dense(256, activation=\"relu\", input_shape=(len(imp_cols)-1,)))\n",
    "#model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model3.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b11d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee0ca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist3 = model3.fit(x=X_train, y=y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daebb306",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model3.evaluate(X_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902602a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model3.predict(X_test)\n",
    "y_pred_binary = []\n",
    "for pred in y_pred:\n",
    "    if pred >= .5:\n",
    "        y_pred_binary.append(1)\n",
    "    else:\n",
    "        y_pred_binary.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dc5005",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_binary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
