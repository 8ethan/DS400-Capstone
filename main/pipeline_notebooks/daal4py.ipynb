{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "997445b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import daal4py\n",
    "import ember_modified\n",
    "from ember_modified.features import PEFeatureExtractor\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19914a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code from 2020 SCARP\n",
    "\n",
    "import numpy as np\n",
    "from daal4py import decision_forest_classification_training, decision_forest_classification_prediction\n",
    "from daal4py import gbt_classification_training, gbt_classification_prediction\n",
    "from daal4py import logistic_regression_training, logistic_regression_prediction\n",
    "from daal4py import kdtree_knn_classification_training, kdtree_knn_classification_prediction\n",
    "from daal4py import svm_training, kernel_function_linear, svm_prediction\n",
    "\n",
    "    \n",
    "class daal_LR: # DAAL Logistic Regression\n",
    "    \"\"\"docstring for Logistic Regression\"\"\"\n",
    "    def __init__(self):\n",
    "        # Model Definition\n",
    "        self.nClasses = 2\n",
    "        self.model = logistic_regression_training(nClasses=self.nClasses, interceptFlag=True)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        # Train the model\n",
    "        self.trainResult = self.model.compute(X_train, np.array(y_train).reshape((len(y_train), 1)))\n",
    "        return self.trainResult.model\n",
    "\n",
    "    def classify(self, data):\n",
    "        self.predictAlgorithm = logistic_regression_prediction(nClasses=self.nClasses) \n",
    "        return self.predictAlgorithm.compute(data, self.trainResult.model).prediction.flatten()\n",
    "\n",
    "\n",
    "\n",
    "class daal_KNN: # DAAL k Nearest Neighbor \n",
    "    \"\"\"docstring for k Nearest Neighbor \"\"\"\n",
    "    def __init__(self, k):\n",
    "        # Model Definition\n",
    "        self.nClasses = 2\n",
    "        self.k=k\n",
    "        self.model = kdtree_knn_classification_training(nClasses=self.nClasses, k=self.k)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        # Train the model\n",
    "        self.trainResult = self.model.compute(X_train, np.array(y_train).reshape((len(y_train), 1)))\n",
    "        return self.trainResult.model\n",
    "\n",
    "    def classify(self, data):\n",
    "        self.predictAlgorithm = kdtree_knn_classification_prediction(nClasses=self.nClasses, k=self.k) \n",
    "        return self.predictAlgorithm.compute(data, self.trainResult.model).prediction.flatten()\n",
    "\n",
    "\n",
    "class daal_DF: # DAAL Decision Forest\n",
    "    \"\"\"docstring for Decision Forest \"\"\"\n",
    "    def __init__(self, n=100, m=10):\n",
    "        # Model Definition\n",
    "        self.nClasses = 2\n",
    "        self.model = decision_forest_classification_training(nClasses=self.nClasses, nTrees=n, maxTreeDepth=m)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        # Train the model\n",
    "        self.trainResult = self.model.compute(X_train, np.array(y_train).reshape((len(y_train), 1)))\n",
    "        return self.trainResult.model\n",
    "\n",
    "    def classify(self, data):\n",
    "        self.predictAlgorithm = decision_forest_classification_prediction(self.nClasses) \n",
    "        return self.predictAlgorithm.compute(data, self.trainResult.model).prediction.flatten()\n",
    "\n",
    "\n",
    "class daal_SVM: # DAAL Support Vector Machine\n",
    "    \"\"\"docstring for Support Vector Machine \"\"\"\n",
    "    def __init__(self, C=1.0, kernel='rbf'):\n",
    "        # Model Definition\n",
    "        self.nClasses = 2\n",
    "        self.kern = kernel_function_linear(method='defaultDense')\n",
    "        self.model = svm_training(nClasses=self.nClasses, C=C, maxIterations=100000, cacheSize=200, kernel=self.kern,\n",
    "                                accuracyThreshold=1e-2, doShrinking=True)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        # Train the model\n",
    "        self.trainResult = self.model.compute(X_train, np.array(y_train).reshape((len(y_train), 1)))\n",
    "        return self.trainResult.model\n",
    "\n",
    "    def classify(self, data):\n",
    "        self.predictAlgorithm = svm_prediction(self.nClasses) \n",
    "        return self.predictAlgorithm.compute(data, self.trainResult.model).prediction.flatten()\n",
    "    \n",
    "class daal_GBT:\n",
    "    def __init__(self, max_iters=50, max_depth=6):\n",
    "        # Model Definition\n",
    "        self.nClasses = 2\n",
    "        self.model = gbt_classification_training(nClasses=self.nClasses, maxIterations=max_iters, maxTreeDepth=max_depth)\n",
    "        self.predictAlgorithm = gbt_classification_prediction(self.nClasses)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        # Train the model\n",
    "        self.trainResult = self.model.compute(X_train, np.array(y_train).reshape((len(y_train), 1)))\n",
    "        return self.trainResult.model\n",
    "\n",
    "    def classify(self, data):\n",
    "        return self.predictAlgorithm.compute(data, self.trainResult.model).prediction.flatten()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae79e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = ember_modified.read_vectorized_features('/home/scarp/ember2018/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63699777",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rows = (y_train != -1)\n",
    "test_rows = (y_test != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3755120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<daal4py._daal4py.logistic_regression_model at 0x7ff63fe96450>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d4p_LR = daal_LR()\n",
    "\n",
    "LR_model = d4p_LR.train(X_train[train_rows], y_train[train_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bf6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_results = d4p_LR.classify(X_test[test_rows])\n",
    "print(accuracy_score(y_test,LR_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40b43542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51796"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test[test_rows],results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab10abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "d4p_DF = daal_DF()\n",
    "\n",
    "DF_model = d4p_DF.train(X_train[train_rows], y_train[train_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81ad1030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892915\n"
     ]
    }
   ],
   "source": [
    "DF_results = d4p_DF.classify(X_test[test_rows])\n",
    "print(accuracy_score(y_test[test_rows],DF_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ead39d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12f02d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d4p_GBT = daal_GBT()\n",
    "\n",
    "GBT_model = d4p_GBT.train(X_train[train_rows], y_train[train_rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "305a825e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94021\n"
     ]
    }
   ],
   "source": [
    "GBT_results = d4p_GBT.classify(X_test[test_rows])\n",
    "print(accuracy_score(y_test[test_rows],GBT_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d3f6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "putty_data = open(\"/home/weitkampe/DS420/FinalProject/test_pes/putty.exe\", \"rb\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d55cc09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = PEFeatureExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75b48311",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.reshape(extractor.feature_vector(putty_data), (1,2381))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e95ada4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ms\n"
     ]
    }
   ],
   "source": [
    "# Check prediction time\n",
    "import time\n",
    "\n",
    "start_time = time.time_ns()\n",
    "prediction = d4p_GBT.classify(features)\n",
    "end_time = time.time_ns()\n",
    "print(str(int((end_time - start_time)/1000000))+\"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fb1f376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max iters: 40\tDepth: 4\tAcc: 0.91204\n",
      "Max iters: 50\tDepth: 4\tAcc: 0.916985\n",
      "Max iters: 60\tDepth: 4\tAcc: 0.920875\n",
      "Max iters: 40\tDepth: 6\tAcc: 0.93464\n",
      "Max iters: 50\tDepth: 6\tAcc: 0.940175\n",
      "Max iters: 60\tDepth: 6\tAcc: 0.94437\n",
      "Max iters: 40\tDepth: 8\tAcc: 0.952785\n",
      "Max iters: 50\tDepth: 8\tAcc: 0.95681\n",
      "Max iters: 60\tDepth: 8\tAcc: 0.958675\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "\n",
    "max_depths = [4,6,8]\n",
    "max_iterations = [40,50,60]\n",
    "#accuracies = []\n",
    "\n",
    "for depth in max_depths:\n",
    "    for num in max_iterations:\n",
    "        \n",
    "        d4p_GBT = daal_GBT(max_iters=num,max_depth=depth)\n",
    "        GBT_model = d4p_GBT.train(X_train[train_rows], y_train[train_rows])\n",
    "        GBT_results = d4p_GBT.classify(X_test[test_rows])\n",
    "        print(\"Max iters: \"+str(num)+\"\\tDepth: \"+str(depth)+\"\\tAcc: \"+str(accuracy_score(y_test[test_rows],GBT_results)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5d5583d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max iters: 60\tDepth: 7\tAcc: 0.952055\n",
      "Max iters: 65\tDepth: 7\tAcc: 0.953885\n",
      "Max iters: 70\tDepth: 7\tAcc: 0.95475\n",
      "Max iters: 60\tDepth: 9\tAcc: 0.9623\n",
      "Max iters: 65\tDepth: 9\tAcc: 0.96465\n",
      "Max iters: 70\tDepth: 9\tAcc: 0.96501\n",
      "Max iters: 60\tDepth: 10\tAcc: 0.96589\n",
      "Max iters: 65\tDepth: 10\tAcc: 0.965875\n",
      "Max iters: 70\tDepth: 10\tAcc: 0.96727\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation 2\n",
    "\n",
    "max_depths = [7,9,10]\n",
    "max_iterations = [60,65,70]\n",
    "#accuracies = []\n",
    "\n",
    "for depth in max_depths:\n",
    "    for num in max_iterations:\n",
    "        \n",
    "        d4p_GBT = daal_GBT(max_iters=num,max_depth=depth)\n",
    "        GBT_model = d4p_GBT.train(X_train[train_rows], y_train[train_rows])\n",
    "        GBT_results = d4p_GBT.classify(X_test[test_rows])\n",
    "        print(\"Max iters: \"+str(num)+\"\\tDepth: \"+str(depth)+\"\\tAcc: \"+str(accuracy_score(y_test[test_rows],GBT_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53df030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max iters: 75\tDepth: 11\tAcc: 0.96978\n",
      "Max iters: 80\tDepth: 11\tAcc: 0.969425\n",
      "Max iters: 90\tDepth: 11\tAcc: 0.97043\n",
      "Max iters: 75\tDepth: 12\tAcc: 0.972405\n",
      "Max iters: 80\tDepth: 12\tAcc: 0.971025\n",
      "Max iters: 90\tDepth: 12\tAcc: 0.972895\n",
      "Max iters: 75\tDepth: 13\tAcc: 0.97203\n",
      "Max iters: 80\tDepth: 13\tAcc: 0.972355\n",
      "Max iters: 90\tDepth: 13\tAcc: 0.971335\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation 3\n",
    "\n",
    "max_depths = [11,12,13]\n",
    "max_iterations = [75,80,90]\n",
    "#accuracies = []\n",
    "\n",
    "for depth in max_depths:\n",
    "    for num in max_iterations:\n",
    "        \n",
    "        d4p_GBT = daal_GBT(max_iters=num,max_depth=depth)\n",
    "        GBT_model = d4p_GBT.train(X_train[train_rows], y_train[train_rows])\n",
    "        GBT_results = d4p_GBT.classify(X_test[test_rows])\n",
    "        print(\"Max iters: \"+str(num)+\"\\tDepth: \"+str(depth)+\"\\tAcc: \"+str(accuracy_score(y_test[test_rows],GBT_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4146db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max iters: 65\tDepth: 12\tAcc: 0.96956\n",
      "Max iters: 70\tDepth: 12\tAcc: 0.971725\n",
      "Max iters: 80\tDepth: 12\tAcc: 0.97131\n",
      "Max iters: 90\tDepth: 12\tAcc: 0.969645\n",
      "Max iters: 95\tDepth: 12\tAcc: 0.97256\n",
      "Max iters: 65\tDepth: 13\tAcc: 0.97081\n",
      "Max iters: 70\tDepth: 13\tAcc: 0.97151\n",
      "Max iters: 80\tDepth: 13\tAcc: 0.97233\n",
      "Max iters: 90\tDepth: 13\tAcc: 0.972525\n",
      "Max iters: 95\tDepth: 13\tAcc: 0.97349\n",
      "Max iters: 65\tDepth: 14\tAcc: 0.97306\n",
      "Max iters: 70\tDepth: 14\tAcc: 0.973695\n",
      "Max iters: 80\tDepth: 14\tAcc: 0.97279\n",
      "Max iters: 90\tDepth: 14\tAcc: 0.974065\n",
      "Max iters: 95\tDepth: 14\tAcc: 0.975085\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation 4\n",
    "\n",
    "max_depths = [12,13,14]\n",
    "max_iterations = [65,70,80,90,95]\n",
    "#accuracies = []\n",
    "\n",
    "for depth in max_depths:\n",
    "    for num in max_iterations:\n",
    "        \n",
    "        d4p_GBT = daal_GBT(max_iters=num,max_depth=depth)\n",
    "        GBT_model = d4p_GBT.train(X_train[train_rows], y_train[train_rows])\n",
    "        GBT_results = d4p_GBT.classify(X_test[test_rows])\n",
    "        print(\"Max iters: \"+str(num)+\"\\tDepth: \"+str(depth)+\"\\tAcc: \"+str(accuracy_score(y_test[test_rows],GBT_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "407faba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max iters: 80\tDepth: 14\tAcc: 0.972855\n",
      "Max iters: 90\tDepth: 14\tAcc: 0.974115\n",
      "Max iters: 100\tDepth: 14\tAcc: 0.97522\n",
      "Max iters: 110\tDepth: 14\tAcc: 0.97439\n",
      "Max iters: 80\tDepth: 15\tAcc: 0.972595\n",
      "Max iters: 90\tDepth: 15\tAcc: 0.974525\n",
      "Max iters: 100\tDepth: 15\tAcc: 0.97473\n",
      "Max iters: 110\tDepth: 15\tAcc: 0.97492\n",
      "Max iters: 80\tDepth: 16\tAcc: 0.973775\n",
      "Max iters: 90\tDepth: 16\tAcc: 0.974055\n",
      "Max iters: 100\tDepth: 16\tAcc: 0.974195\n",
      "Max iters: 110\tDepth: 16\tAcc: 0.97313\n",
      "Max iters: 80\tDepth: 17\tAcc: 0.97331\n",
      "Max iters: 90\tDepth: 17\tAcc: 0.97298\n",
      "Max iters: 100\tDepth: 17\tAcc: 0.97459\n",
      "Max iters: 110\tDepth: 17\tAcc: 0.97418\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation 5\n",
    "\n",
    "max_depths = [14,15,16,17]\n",
    "max_iterations = [80,90,100,110]\n",
    "#accuracies = []\n",
    "\n",
    "for depth in max_depths:\n",
    "    for num in max_iterations:\n",
    "        \n",
    "        d4p_GBT = daal_GBT(max_iters=num,max_depth=depth)\n",
    "        GBT_model = d4p_GBT.train(X_train[train_rows], y_train[train_rows])\n",
    "        GBT_results = d4p_GBT.classify(X_test[test_rows])\n",
    "        print(\"Max iters: \"+str(num)+\"\\tDepth: \"+str(depth)+\"\\tAcc: \"+str(accuracy_score(y_test[test_rows],GBT_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f244581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max iters: 100\tDepth: 14\tAcc: 0.97522"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa52f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profiling from 2020 SCARP\n",
    "# Spark Streaming using sklearn model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
